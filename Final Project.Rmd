---
title: "Final Project - House analysis"
author: "Deen Huang"
date: "12/11/2017"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r}
house <- data.frame(read.csv("house.csv"))
head(house)
names(house)
dim(house)
summary(house)
```

#**Descriptive Statistics**
```{r}
str(house)
```

price: price
bedrooms: number of bedrooms
bathrooms: number of bathrooms
sqft_living: square footage of the home
sqft_lot: square footage of the lot
floors: total floors (levels) in house
view: house which has been viewed
condition: how good the condition is (overall)
grade: overall grade given to the housing unit, based on King County grading system
sqft_above: square footage of house apart from basement
sqft_basement: square footage of the basement
yr_built: built year
lat: latitude coordinate
long: longtitude coordinate

#Graphical representations
#**Boxplot for all 14 variables**
```{r}
boxplot(house)
```
#**Boxplot for each of 14 variables**
```{r}
boxplot(house$price, xlab = "Price")

boxplot(house$bedrooms, xlab = "Bedrooms")

boxplot(house$bathrooms, xlab = "Bathrooms")

boxplot(house$sqft_living, xlab = "Sqft_living")

boxplot(house$sqft_lot, xlab = "Sqft_lot")

boxplot(house$floors, xlab = "Floors")

boxplot(house$view, xlab = "View")

boxplot(house$condition, xlab = "Condition")

boxplot(house$grade, xlab = "grade")

boxplot(house$sqft_above, xlab = "sqft_above")

boxplot(house$sqft_basement, xlab = "sqft_basement")

boxplot(house$yr_built, xlab = "yr_bulit")

boxplot(house$lat, xlab = "lat")

boxplot(house$long, xlab = "long")
```
From the boxplots of each one variable, we saw a lot of outliers, so before doing the model selection and the further steps, we need to clean the data first.

#**remove ourlier**
```{r, eval=TRUE}
outlierKD <- function(dt, var) { 
     var_name <- eval(substitute(var),eval(dt))
     na1 <- sum(is.na(var_name))
     m1 <- mean(var_name, na.rm = T)
     par(mfrow=c(2, 2), oma=c(0,0,3,0))
     boxplot(var_name, main="With outliers")
     hist(var_name, main="With outliers", xlab=NA, ylab=NA)
     outlier <- boxplot.stats(var_name)$out
     mo <- mean(outlier)
     var_name <- ifelse(var_name %in% outlier, NA, var_name)
     boxplot(var_name, main="Without outliers")
     hist(var_name, main="Without outliers", xlab=NA, ylab=NA)
     title("Outlier Check", outer=TRUE)
     na2 <- sum(is.na(var_name))
     cat("Outliers identified:", na2 - na1, "n")
     cat("Propotion (%) of outliers:", round((na2 - na1) / sum(!is.na(var_name))*100, 1), "n")
     cat("Mean of the outliers:", round(mo, 2), "n")
     m2 <- mean(var_name, na.rm = T)
     cat("Mean without removing outliers:", round(m1, 2), "n")
     cat("Mean if we remove outliers:", round(m2, 2), "n")
     response <- readline(prompt="Do you want to remove outliers and to replace with NA? [yes/no]: ")
     if(response == "y" | response == "yes"){
          dt[as.character(substitute(var))] <- invisible(var_name)
          assign(as.character(as.list(match.call())$dt), dt, envir = .GlobalEnv)
          cat("Outliers successfully removed", "n")
          return(invisible(dt))
     } else{
          cat("Nothing changed", "n")
          return(invisible(var_name))
     }
}
```
# running the outlierKD code below triggers a prompt on the console window (yes/no). Answer there to proceed.
```{r}
outlierKD(house, price)
```
```{r}
outlierKD(house, bedrooms)
```
```{r}
outlierKD(house, bathrooms)
```
```{r}
outlierKD(house, sqft_living)
```
```{r}
outlierKD(house, sqft_lot)
```
```{r}
outlierKD(house, condition)
```
```{r}
outlierKD(house, grade)
```
```{r}
outlierKD(house, sqft_above)
```
```{r}
#outlierKD(house, sqft_basement)
```
```{r}
outlierKD(house, lat)
```
```{r}
outlierKD(house, long)
```
Next, need to take a look at Q-Q plot to make sure variables are being more or less normal
#Q-Qplot
```{r}
hist(house$price, main = "price", xlab = 'price', col = 'blue')
qqnorm(house$price)
qqline(house$price)

hist(house$bedrooms, main = "bedrooms", xlab = 'bedrooms', col = 'blue')
qqnorm(house$bedrooms)
qqline(house$bedrooms)

hist(house$bathrooms, main = "bathrooms", xlab = 'bathrooms', col = 'blue')
qqnorm(house$bathrooms)
qqline(house$bathrooms)

hist(house$sqft_living, main = "sqft_living", xlab = 'sqft_living', col = 'blue')
qqnorm(house$sqft_living)
qqline(house$sqft_living)

hist(house$sqft_lot, main = "sqft_lot", xlab = 'sqft_lot', col = 'blue')
qqnorm(house$sqft_lot)
qqline(house$sqft_lot)

hist(house$sqft_lot, main = "sqft_lot", xlab = 'sqft_lot', col = 'blue')
qqnorm(house$sqft_lot)
qqline(house$sqft_lot)

hist(house$floors, main = "floors", xlab = 'floors', col = 'blue')
qqnorm(house$floors)
qqline(house$floors)

hist(house$view, main = "view", xlab = 'view', col = 'blue')
qqnorm(house$view)
qqline(house$view)

hist(house$condition, main = "condition", xlab = 'condition', col = 'blue')
qqnorm(house$condition)
qqline(house$condition)

hist(house$grade, main = "grade", xlab = 'grade', col = 'blue')
qqnorm(house$grade)
qqline(house$grade)

hist(house$sqft_above, main = "sqft_above", xlab = 'sqft_above', col = 'blue')
qqnorm(house$sqft_above)
qqline(house$sqft_above)

hist(house$sqft_basement, main = "sqtf_basement", xlab = 'sqft_basement', col = 'blue')
qqnorm(house$sqft_basement)
qqline(house$sqft_basement)

hist(house$yr_built, main = "yr_built", xlab = 'yr_built', col = 'blue')
qqnorm(house$yr_built)
qqline(house$yr_built)

hist(house$lat, main = "lat", xlab = 'lat', col = 'blue')
qqnorm(house$lat)
qqline(house$lat)

hist(house$long, main = "long", xlab = 'long', col = 'blue')
qqnorm(house$long)
qqline(house$long)
```

#Fitting the model
```{r}
fit <- lm(price~.,data = house)
summary(fit)
```
In our model, we choose "price' as the dependent variable. We would like to figure the significant factors affecting the housing price. To do the model fitting, firstly we want to get the overview of the trend of how every variable influences the house price. So we do the linear regression based on full model. The Adjusted R2 is 0.6526, close to 0.7. That means almost 70% of the price can be explained by these variables.
Then we focus on the estimated coefficients. 

```{r}
coefficients(fit) # model coefficients
confint(fit, level=0.95) # CIs for model parameters 
fitted(fit) # predicted values
residuals(fit) # residuals
anova(fit) # anova table 
vcov(fit) # covariance matrix for model parameters 
influence(fit) # regression diagnostics
```
# check for heteroskedasticity, normality, and influential observations
```{r}
# diagnostic plots 
layout(matrix(c(1,2,3,4),2,2)) # optional 4 graphs/page 
plot(fit)
```

Even though there are still some outliers exists from the residuals vs fitted graphic, the most part of the values are equally separated on two sides. So based on the graphics above, we can do linear regression model test.
# best fit
```{r}
library(leaps)
reg.best <- regsubsets(price~., data = house, nvmax = 2)
reg.best
plot(reg.best,scale = "adjr2",main = "adjr2")
plot(reg.best, scale = "bic", main = "BIC")
plot(reg.best, scale = "Cp", main = "Cp")
summary(reg.best)
```
From the adjusted-R^2 table, the model with sqft_living, grade, and long (and the intercept) has the largest adjusted-R^2 (adjusted-R^2 = 0.56). The next best model has sqft_living, grade, and long, with adjusted-R^2 = 0.56; the third best has grade only with adjusted-R^2 = 0.29. So right now, we make an expectation that the sqft_living, grade and long affect the housing price most. Next, we will use backward selection, forward selection, and hybrid selection to confirm which model is the best linear model.

# backward variable selection
```{r}
reg.back <- regsubsets(price~., data = house, method = "backward", nvmax = 2)
plot(reg.back, scale = "adjr2", main = "Adjusted R^2")
plot(reg.back, scale = "bic", main = "BIC")
plot(reg.back, scale = "Cp", main = "Cp")
summary(reg.back)
```

After doing the backward selection, the result is the same as before: the model with sqft_living, and long (and the intercept) has the largest adjusted-R^2 (adjusted-R^2 = 0.51). The next best model has sqft_living, long, with adjusted-R^2 = 0.51; the third best has sqft_living, with adjusted-R^2 = 0.28.

# forward variable selection
```{r}
reg.forward <- regsubsets(price~., data = house, nbest = 1, method = "forward", nvmax = 2)
summary(reg.forward)
plot(reg.forward, scale = "adjr2", main = "Adjusted R^2")
plot(reg.forward, scale = "bic", main = "BIC")
plot(reg.forward, scale = "Cp", main = "Cp")
reg.forward
```

The forward selection shows exactly the same result as backward selection as the model with sqft_living, grade, and long (and the intercept) has the largest adjusted-R^2 (adjusted-R^2 = 0.56).

Even though the second best and third best model is slightly different in two different selection models, the best one is the same.

# hybrid variable selection
```{r}
#Lastly we can do the hybrid approach
reg.seqrep <- regsubsets(price~., data = house, nbest = 1, method = "seqrep", nvmax = 2)
plot(reg.seqrep, scale = "adjr2", main = "Adjusted R^2")
plot(reg.seqrep, scale = "Cp", main = "Cp")
summary(reg.seqrep)
```

When we do the hybrid selection, it provides the information as follows: from the adjusted-R^2 table, the model with sqft_living, grade, and long (and the intercept) has the highest adjusted-R^2 (=0.56). The next best model has sqft_living, and long, with adjusted-R^2=0.51; the third best has grade only, with adjusted-R^2=0.29.

So, right now, we can conclude that sqft_living, grade and long are three most significant variables to explain housing prices.

# regression model
```{r}
house_var <- c("price","sqft_living","grade", "long" )
house_new <- house[house_var]
fit_new <- lm(price~., data=house_new)
```

# check multicolinearity
```{r}
library("olsrr")
ols_coll_diag(fit_new)
```
Variance inflation factors (VIF) measures how much the variance of estimated regression is inflated by the existence of correlation among the predictor variables. A VIF of 1 means that there is no correlation among the predictor and the remaining predictor variables. Since all 3 variables have VIF less than 4 (all less than 2), we can conclude that there is no correlation among the predictor variables.

# prediction
```{r}
summary(fit_new)
```
So we predict that the housing price is related to the square footage of the home, the overall grade given to the housing unit, based on King County grading system, and the longtitude coordinate. And our prediction model is shown as following:
Price = 107.4*sqft_living + 80310*grade - 222400*long - 2.75*10^7